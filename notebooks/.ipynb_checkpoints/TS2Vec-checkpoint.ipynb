{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# os.chdir('src/models/ts2vec_src')\n",
    "from src.data.preprocessing import read_data, data_to_np_tensor, preprocess_split\n",
    "from src.models.ts2vec_src.ts2vec import TS2Vec\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_data('data/all_tickers.csv')\n",
    "# train_data = preprocessing(\n",
    "#     data, \n",
    "#     ['Open', 'High', 'Low', 'Close', 'Volume'],         \n",
    "#     start_date = '2023-12-15',\n",
    "#     end_date = '2023-12-21'\n",
    "# )\n",
    "\n",
    "# test_data = preprocessing(\n",
    "#     data, \n",
    "#     ['Open', 'High', 'Low', 'Close', 'Volume'],          \n",
    "#     start_date = '2023-12-21',\n",
    "#     end_date = '2023-12-22',\n",
    "#     tickers_save = train_data['Close'].columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "#     print(train_data['Close'].shape[1], test_data['Close'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ts = data_to_np_tensor(train_data)\n",
    "# test_ts = data_to_np_tensor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TS2Vec(\n",
    "#     input_dims=train_ts.shape[2],\n",
    "#     device=1,\n",
    "#     output_dims=320\n",
    "# )\n",
    "\n",
    "# loss_log = model.fit(\n",
    "#     train_ts,\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# test_repr = model.encode(test_ts)\n",
    "# #test_repr = model.encode(test_data, encoding_window='full_series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_repr = model.encode(test_ts, encoding_window='full_series')\n",
    "# print(test_repr.shape)\n",
    "# test_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean stock price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/best_stocks_nans_rate.yaml') as f:\n",
    "    best_stocks = yaml.load(f, Loader=yaml.FullLoader)\n",
    "best_stocks = list(best_stocks.keys())\n",
    "# best_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data('data/all_tickers.csv')\n",
    "df_best = df.query(\"Stock in @best_stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Stock'].apply(lambda x: x in best_stocks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_h = df_best.set_index('Datetime').groupby(\n",
    "    ['Stock', pd.Grouper(freq='h')],\n",
    ").agg(dd)\n",
    "\n",
    "df_best_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_best_h.groupby('Stock').pct_change().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end = '2023-10-01', '2023-11-01'\n",
    "test_start, test_end = '2023-11-01', '2023-11-07'\n",
    "\n",
    "\n",
    "train_data = preprocess_split(\n",
    "    df, \n",
    "    ['Open', 'High', 'Low', 'Close', 'Volume'],         \n",
    "    start_date = train_start,\n",
    "    end_date = train_end,\n",
    "    tickers_save = best_stocks\n",
    ")\n",
    "\n",
    "test_data = preprocess_split(\n",
    "    df, \n",
    "    ['Open', 'High', 'Low', 'Close', 'Volume'],          \n",
    "    start_date = test_start,\n",
    "    end_date = test_end,\n",
    "    tickers_save = best_stocks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts = data_to_np_tensor(train_data)\n",
    "test_ts = data_to_np_tensor(test_data)\n",
    "\n",
    "train_ts.shape, test_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TS2Vec(\n",
    "    input_dims=train_ts.shape[2],\n",
    "    device='cpu', ###### 2\n",
    "    output_dims=128\n",
    ")\n",
    "\n",
    "loss_log = model.fit(\n",
    "    train_ts,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_repr = model.encode(train_ts)\n",
    "test_repr = model.encode(test_ts)\n",
    "\n",
    "train_repr.shape, test_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_embeddigns_to_df(data_tensor: np.ndarray, stocks, dates) -> dict:    \n",
    "    res = pd.DataFrame()\n",
    "    for i, stock in enumerate(stocks):\n",
    "        df = pd.DataFrame(data_tensor[i], index=dates)\n",
    "        df.columns = ['emb_' + str(i) for i in range(len(df.columns))]\n",
    "        df['Stock'] = stock\n",
    "        res = pd.concat([res, df])\n",
    "\n",
    "    return res.reset_index(drop=False, names='Datetime')\n",
    "\n",
    "X_train = stock_embeddigns_to_df(train_repr, stocks=train_data['Open'].columns, dates=train_data['Open'].index)\n",
    "X_test = stock_embeddigns_to_df(test_repr, stocks=test_data['Open'].columns, dates=test_data['Open'].index)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emd = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_best.set_index('Datetime').groupby(\n",
    "    ['Stock', pd.Grouper( freq='h')],\n",
    ").agg({'Close': 'mean'}).reset_index()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end = '2023-10-01', '2023-11-01'\n",
    "test_start, test_end = '2023-11-01', '2023-11-07'\n",
    "\n",
    "y_train = y[(y['Datetime'].dt.date >= pd.Timestamp(train_start).date()) & \n",
    "             (y['Datetime'].dt.date < pd.Timestamp(train_end).date())]\n",
    "\n",
    "y_test = y[(y['Datetime'].dt.date >= pd.Timestamp(test_start).date()) & \n",
    "             (y['Datetime'].dt.date < pd.Timestamp(test_end).date())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emd = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_emd.to_csv('results/TS2Vec/x_emb.csv', index=False)\n",
    "# y_emd.to_csv('results/TS2Vec/y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'Close'\n",
    "\n",
    "df_train = pd.merge(X_train, y_train, on=['Stock', 'Datetime'])\n",
    "df_test = pd.merge(X_test, y_test, on=['Stock', 'Datetime'])\n",
    "\n",
    "X_train, y_train = df_train.drop(columns=[y_name, 'Datetime', 'Stock']), df_train[y_name]\n",
    "X_test, y_test = df_test.drop(columns=[y_name, 'Datetime', 'Stock']), df_test[y_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "MAE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_baseline = df.set_index('Datetime').groupby(\n",
    "    ['Stock', pd.Grouper( freq='h')],\n",
    ").agg({'Close': 'mean'}).reset_index()\n",
    "X_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_vals = df_best_h.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shifts = 18\n",
    "for i in range(1, n_shifts + 1):\n",
    "    X_baseline[f'shift_{i}'] = X_baseline.groupby(by=['Stock']).shift(i)['Close']\n",
    "\n",
    "X_baseline = X_baseline.dropna()\n",
    "y = X_baseline.loc[:, :'Close'] \n",
    "\n",
    "X_baseline = X_baseline.drop(columns='Close')\n",
    "X_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end = '2023-10-01', '2023-11-01'\n",
    "test_start, test_end = '2023-11-01', '2023-11-07'\n",
    "\n",
    "y_train = y[(y['Datetime'].dt.date >= pd.Timestamp(train_start).date()) & \n",
    "             (y['Datetime'].dt.date < pd.Timestamp(train_end).date())]['Close']\n",
    "\n",
    "y_test = y[(y['Datetime'].dt.date >= pd.Timestamp(test_start).date()) & \n",
    "             (y['Datetime'].dt.date < pd.Timestamp(test_end).date())]['Close']\n",
    "\n",
    "X_train = X_baseline[(X_baseline['Datetime'].dt.date >= pd.Timestamp(train_start).date()) & \n",
    "             (X_baseline['Datetime'].dt.date < pd.Timestamp(train_end).date())]\n",
    "\n",
    "X_test = X_baseline[(X_baseline['Datetime'].dt.date >= pd.Timestamp(test_start).date()) & \n",
    "             (X_baseline['Datetime'].dt.date < pd.Timestamp(test_end).date())]\n",
    "\n",
    "last_train_date = X_train.groupby(['Stock'], as_index=False).last()[['Stock', 'Datetime']]\n",
    "y_start_test = orig_vals.merge(last_train_date, how='inner', on=['Stock', 'Datetime'])\n",
    "y_start_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train.drop(['Stock', 'Datetime'], axis=1), y_train)\n",
    "y_pred = model.predict(X_test.drop(['Stock', 'Datetime'], axis=1))\n",
    "\n",
    "MAE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = X_test[['Stock', 'Datetime']].copy()\n",
    "df_preds['Preds'] = y_pred + 1\n",
    "df_preds['Close'] = y_test + 1\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = y_start_test.sort_values('Stock')['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_close = df_preds.pivot(columns=['Stock'], index='Datetime', values=['Preds']).cumprod() * starts\n",
    "orig_close = df_preds.pivot(columns=['Stock'], index='Datetime', values=['Close']).cumprod() * starts\n",
    "\n",
    "pred_close = pred_close['Preds'].reset_index().melt(id_vars=['Datetime'])\n",
    "orig_close = orig_close['Close'].reset_index().melt(id_vars=['Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline + TS2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_test = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_embeddigns_to_df(data_tensor: np.ndarray, stocks, dates) -> dict:    \n",
    "    res = pd.DataFrame()\n",
    "    for i, stock in enumerate(stocks):\n",
    "        df = pd.DataFrame(data_tensor[i], index=dates)\n",
    "        df.columns = ['emb_' + str(i) for i in range(len(df.columns))]\n",
    "        df['Stock'] = stock\n",
    "        res = pd.concat([res, df])\n",
    "\n",
    "    return res.reset_index(drop=False, names='Datetime')\n",
    "\n",
    "X_train = stock_embeddigns_to_df(train_repr, stocks=train_data['Open'].columns, dates=train_data['Open'].index)\n",
    "X_test = stock_embeddigns_to_df(test_repr, stocks=test_data['Open'].columns, dates=test_data['Open'].index)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_best.set_index('Datetime').groupby(\n",
    "    ['Stock', pd.Grouper( freq='h')],\n",
    ").agg({'Close': 'mean'}).reset_index()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end = '2023-10-01', '2023-11-01'\n",
    "test_start, test_end = '2023-11-01', '2023-11-07'\n",
    "\n",
    "y_train = y[(y['Datetime'].dt.date >= pd.Timestamp(train_start).date()) & \n",
    "             (y['Datetime'].dt.date < pd.Timestamp(train_end).date())]\n",
    "\n",
    "y_test = y[(y['Datetime'].dt.date >= pd.Timestamp(test_start).date()) & \n",
    "             (y['Datetime'].dt.date < pd.Timestamp(test_end).date())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'Close'\n",
    "\n",
    "df_train = pd.merge(X_train, y_train, on=['Stock', 'Datetime'])\n",
    "df_test = pd.merge(X_test, y_test, on=['Stock', 'Datetime'])\n",
    "\n",
    "X_train, y_train = df_train.drop(columns=[y_name, 'Datetime', 'Stock']), df_train[y_name]\n",
    "X_test, y_test = df_test.drop(columns=[y_name, 'Datetime', 'Stock']), df_test[y_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, shifts], axis=1)\n",
    "X_test = pd.concat([X_test, shifts_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "MAE(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
